version: "3.8"
services:
  # Auth Service và các dependencies
  auth-service:
    build: ./backend/auth_service_fastapi
    container_name: auth-service
    restart: unless-stopped
    ports:
      - "8800:8800"
    env_file:
      - .env
    depends_on:
      rumai-db:
        condition: service_healthy
      redis:
        condition: service_started
    networks:
      - rumai_network
      - api-gateway-network    # Thêm network mới
    healthcheck:              # Thêm healthcheck cho auth service
      test: ["CMD", "curl", "-f", "http://localhost:8800/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'

  # OCR Service
  ocr-service:
    build: ./backend/ocr_service_fastapi
    container_name: ocr-service
    restart: unless-stopped
    ports:
      - "8810:8810"
    env_file:
      - .env
    volumes:
#      - ./backend/ocr_service_fastapi:/app
      - ./keys:/app/keys:ro # Mount thư mục chỉ đọc chứa credentials
    environment:
      - GOOGLE_APPLICATION_CREDENTIALS=/app/keys/google-vision-key.json
      - AUTH_SERVICE_URL=https://api.rumai.app  # Đảm bảo URL này chính xác
    depends_on:
      auth-service:
        condition: service_healthy
    networks:
      - rumai_network
      - api-gateway-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8810/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.5'
        reservations:
          memory: 512M
          cpus: '0.5'

## Custom OCR Service
#  ocr-custom-service:
#    build: ./backend/ocr_custom_service_fastapi
#    container_name: ocr-custom-service
#    restart: unless-stopped
#    ports:
#      - "8811:8811"
#    env_file:
#      - .env
#    environment:
#      - AUTH_SERVICE_URL=https://api.rumai.app
#    depends_on:
#      auth-service:
#        condition: service_healthy
#    networks:
#      - rumai_network
#      - api-gateway-network
#    healthcheck:
#      test: ["CMD", "curl", "-f", "http://localhost:8811/health"]
#      interval: 30s
#      timeout: 10s
#      retries: 3
#      start_period: 60s
#    deploy:
#      resources:
#        limits:
#          memory: 4G  # ML models require more memory

  rumai-db:
    image: postgres:13
    restart: unless-stopped
    environment:
      - POSTGRES_USER=${DB_USER}
      - POSTGRES_PASSWORD=${DB_PASSWORD}
      - POSTGRES_DB=${DB_NAME}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5433:5432"
    networks:
      - rumai_network
    healthcheck:
      test: [ "CMD", "pg_isready", "-U", "${DB_USER}", "-d", "${DB_NAME}" ]
      interval: 5s
      timeout: 5s
      retries: 5
    command: postgres -c shared_buffers=256MB -c max_connections=100
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1'

  redis:
    image: redis:6
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - rumai_network
    command: redis-server --maxmemory 256mb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 300mb
        reservations:
          memory: 100mb
    ulimits:
      nofile:
        soft: 65536
        hard: 65536

  # Kong Gateway và các dependencies
  kong-database:
    image: postgres:13
    container_name: kong-database
    restart: unless-stopped
    environment:
      POSTGRES_USER: kong
      POSTGRES_DB: kong
      POSTGRES_PASSWORD: kong
    volumes:
      - kong-data:/var/lib/postgresql/data
    ports:
      - "5435:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U kong"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - kong-net

  kong:
    image: kong:latest
    container_name: kong
    restart: unless-stopped
    depends_on:
      kong-database:
        condition: service_healthy
    environment:
      KONG_DATABASE: postgres
      KONG_PG_HOST: kong-database
      KONG_PG_PASSWORD: kong
      KONG_PROXY_ACCESS_LOG: /dev/stdout
      KONG_ADMIN_ACCESS_LOG: /dev/stdout
      KONG_PROXY_ERROR_LOG: /dev/stderr
      KONG_ADMIN_ERROR_LOG: /dev/stderr
      KONG_ADMIN_LISTEN: 0.0.0.0:8001, 0.0.0.0:8444 ssl
    ports:
      - "7000:8000"    # Proxy listener
      - "7443:8443"    # Proxy SSL listener
      - "7001:8001"    # Admin API
      - "7444:8444"    # Admin API SSL
    command: |
      sh -c "kong migrations bootstrap && kong start"
    networks:
      - kong-net
      - api-gateway-network    # Thêm network mới
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1'
        reservations:
          memory: 512M
          cpus: '0.5'

  konga:
    image: pantsel/konga:latest
    container_name: konga
    restart: unless-stopped
    depends_on:
      - kong
    environment:
      - NODE_ENV=production
      - TOKEN_SECRET=supersecret
      - KONGA_BACKEND_URL=http://kong:8001
    ports:
      - "7337:1337"
    networks:
      - kong-net

  prometheus:
    image: prom/prometheus
    container_name: prometheus
    restart: unless-stopped
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"
    networks:
      - monitoring-net
      - kong-net

  grafana:
    image: grafana/grafana
    container_name: grafana
    restart: unless-stopped
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    ports:
      - "3000:3000"
    networks:
      - monitoring-net
    depends_on:
      - prometheus
    volumes:
      - grafana_data:/var/lib/grafana

  uptime-kuma:
    image: louislam/uptime-kuma:latest
    container_name: uptime-kuma
    restart: unless-stopped
    volumes:
      - uptime-kuma-data:/app/data
    ports:
      - "3001:3001"  # Port mặc định của Uptime Kuma
    networks:
      - monitoring-net
#    healthcheck:
#      test: ["CMD", "wget", "--spider", "http://localhost:3001"]
#      interval: 30s
#      timeout: 10s
#      retries: 3

  gemini-service:
    build: ./backend/gemini_service
    container_name: gemini-service
    restart: unless-stopped
    ports:
      - "6161:6161" # Port defined in gemini_service/main.py
    env_file:
      - .env # Loads GOOGLE_API_KEY etc.
    networks:
      - rumai_network # Internal communication with exercise_management_service
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6161/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'

#  exercise-management-service:
#    build: ./backend/exercise_management_service
#    container_name: exercise-management-service
#    restart: unless-stopped
#    ports:
#      - "8002:8002" # Port defined in exercise_management_service/main.py
#    env_file:
#      - .env # Loads DB creds, admin creds, JWT secrets, GEMINI_SERVICE_URL etc.
#    depends_on:
#      exercise-db:
#        condition: service_healthy
#      gemini-service:
#        condition: service_healthy # Wait for gemini service to be healthy
#    networks:
#      - rumai_network
#      - api-gateway-network # Assuming this service will be exposed via Kong
#    healthcheck:
#      # Basic check, TODO: improve to check DB connection later
#      test: ["CMD", "curl", "-f", "http://localhost:8002/api/v1/health"]
#      interval: 30s
#      timeout: 10s
#      retries: 3
#      start_period: 45s # Give it more time due to DB dependency
#    deploy:
#      resources:
#        limits:
#          memory: 1G # May need more depending on data load
#          cpus: '1'
#        reservations:
#          memory: 512M
#          cpus: '0.5'
#
#  exercise-db:
#    image: postgres:13 # Or a newer version like postgres:16
#    container_name: exercise-db
#    restart: unless-stopped
#    environment:
#      # Use specific env vars for this DB, defined in the main .env file
#      POSTGRES_USER: ${EXERCISE_DB_USER:-exercise_user}
#      POSTGRES_PASSWORD: ${EXERCISE_DB_PASSWORD:-exercise_password}
#      POSTGRES_DB: ${EXERCISE_DB_NAME:-exercise_db}
#    volumes:
#      - exercise_postgres_data:/var/lib/postgresql/data
#    ports:
#      - "5434:5432" # Different port from rumai-db and kong-database
#    networks:
#      - rumai_network
#    healthcheck:
#      test: [ "CMD", "pg_isready", "-U", "${EXERCISE_DB_USER:-exercise_user}", "-d", "${EXERCISE_DB_NAME:-exercise_db}" ]
#      interval: 5s
#      timeout: 5s
#      retries: 5
#    deploy:
#      resources:
#        limits:
#          memory: 1G
#          cpus: '1'


networks:
  rumai_network:
    driver: bridge
  kong-net:
    driver: bridge
  monitoring-net:
    driver: bridge
  api-gateway-network:    # Định nghĩa network mới
    driver: bridge
    internal: true       # Chỉ cho phép giao tiếp nội bộ
    name: api-gateway-network

volumes:
  grafana_data:
  postgres_data:
  redis_data:
  kong-data:
  uptime-kuma-data:
  exercise_postgres_data: # Volume for the new exercise database